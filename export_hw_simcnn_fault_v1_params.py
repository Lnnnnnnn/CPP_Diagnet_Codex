#!/usr/bin/env python3
"""Export HW_SimCNNFault_V1 PyTorch weights to a C++ include fragment.

This script loads a training checkpoint (.pth) saved from HW_SimCNNFault_V1
and emits a C++ snippet that assigns every weight/bias/BN buffer in
HW_SimCNNFault_V1.cpp. Include the generated file by defining
`HW_SIMCNNFAULT_V1_USE_TRAINED_PARAMS` (and optionally overriding
`HW_SIMCNNFAULT_V1_PARAMS_FILE`) when building the HLS C++.

Example:
    python export_hw_simcnn_fault_v1_params.py \
        --ckpt path/to/model.pth \
        --output HW_SimCNNFault_V1_params.inc

    # In your synthesis compile flags:
    -DHW_SIMCNNFAULT_V1_USE_TRAINED_PARAMS
    -DHW_SIMCNNFAULT_V1_PARAMS_FILE=\"HW_SimCNNFault_V1_params.inc\"

The generated file is not guarded; it is meant to be consumed inside
init_demo_params() via `#include`. Do not edit by hand.
"""

import argparse
from pathlib import Path
from typing import Tuple

import torch

from HW_SimCNNFault_V1 import HW_SimCNNFault_V1


def _write_header(f, ckpt: Path):
    f.write("// Auto-generated by export_hw_simcnn_fault_v1_params.py\n")
    f.write(f"// Source checkpoint: {ckpt}\n\n")


def _emit_assign(f, name: str, index: Tuple[int, ...], value: float):
    idx = "".join(f"[{i}]" for i in index)
    f.write(f"{name}{idx} = {float(value):.9g};\n")


def _emit_conv1d(f, prefix: str, weight, bias):
    # PyTorch Conv1d weights: (out_ch, in_ch, k)
    out_ch, in_ch, k = weight.shape
    bias_val = bias if bias is not None else torch.zeros(out_ch)

    for o in range(out_ch):
        _emit_assign(f, f"{prefix}_B", (o,), bias_val[o].item())
    for o in range(out_ch):
        for c in range(in_ch):
            for kk in range(k):
                _emit_assign(
                    f,
                    f"{prefix}_W",
                    (0, kk, c, o),
                    weight[o, c, kk].item(),
                )


def _emit_bn(f, prefix: str, bn):
    gamma = bn.weight
    beta = bn.bias
    mean = bn.running_mean
    var = bn.running_var
    for i in range(gamma.numel()):
        _emit_assign(f, f"{prefix}_BN_GAMMA", (i,), gamma[i].item())
        _emit_assign(f, f"{prefix}_BN_BETA", (i,), beta[i].item())
        _emit_assign(f, f"{prefix}_BN_MEAN", (i,), mean[i].item())
        _emit_assign(f, f"{prefix}_BN_VAR", (i,), var[i].item())


def _emit_fc(f, prefix: str, weight, bias):
    # Linear weight: (out_dim, in_dim) -> stored as w[in][out]
    out_dim, in_dim = weight.shape
    for o in range(out_dim):
        _emit_assign(f, f"{prefix}_B", (o,), bias[o].item())
    for o in range(out_dim):
        for i in range(in_dim):
            _emit_assign(f, f"{prefix}_W", (i, o), weight[o, i].item())


def _emit_attention(f, att: HW_SimCNNFault_V1):
    conv1 = att.attention.conv1
    conv2 = att.attention.conv2

    # conv1: (32, 64, 1) -> ATT1_W[64][32]
    _emit_conv1d(f, "ATT1", conv1.weight, conv1.bias)

    # conv2: (64, 32, 1) -> ATT2_W[32][64]
    _emit_conv1d(f, "ATT2", conv2.weight, conv2.bias)


def export_params(ckpt: Path, output: Path, device: str = "cpu"):
    model = HW_SimCNNFault_V1()
    state = torch.load(ckpt, map_location=device)
    if isinstance(state, dict) and "state_dict" in state:
        state = state["state_dict"]

    if all(k.startswith("module.") for k in state.keys()):
        state = {k[len("module.") :]: v for k, v in state.items()}
    if all(k.startswith("model.") for k in state.keys()):
        state = {k[len("model.") :]: v for k, v in state.items()}

    model.load_state_dict(state)
    model.eval()

    # Basic sanity: ensure unfused layout exists
    missing = [k for k in ["conv3.weight", "conv5.weight"] if k not in state]
    if missing:
        raise RuntimeError(
            "Checkpoint appears to be in deploy/fused mode; expected conv3/conv5 branches."
        )

    with output.open("w", encoding="utf-8") as f:
        _write_header(f, ckpt)

        stem_conv = model.stem[0]
        stem_bn = model.stem[1]
        _emit_conv1d(f, "STEM", stem_conv.weight, stem_conv.bias)
        _emit_bn(f, "STEM", stem_bn)

        _emit_conv1d(f, "BRANCH3", model.conv3.weight, model.conv3.bias)
        _emit_conv1d(f, "BRANCH5", model.conv5.weight, model.conv5.bias)
        _emit_bn(f, "BRANCH3", model.bn3)
        _emit_bn(f, "BRANCH5", model.bn5)

        block2_conv = model.block2[0]
        block2_bn = model.block2[1]
        _emit_conv1d(f, "BLOCK2", block2_conv.weight, block2_conv.bias)
        _emit_bn(f, "BLOCK2", block2_bn)

        block3_conv = model.block3[0]
        block3_bn = model.block3[1]
        _emit_conv1d(f, "BLOCK3", block3_conv.weight, block3_conv.bias)
        _emit_bn(f, "BLOCK3", block3_bn)

        _emit_attention(f, model)

        fc1 = model.fc_out[0]
        fc2 = model.fc_out[3]
        _emit_fc(f, "FC1", fc1.weight, fc1.bias)
        _emit_fc(f, "FC2", fc2.weight, fc2.bias)

        f.write("\nparams_initialized = true;\n")

    print(f"Wrote trained parameters to {output}")


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--ckpt", required=True, type=Path, help="Path to .pth checkpoint")
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("HW_SimCNNFault_V1_params.inc"),
        help="Destination include fragment",
    )
    parser.add_argument(
        "--device", type=str, default="cpu", help="torch device for loading (default: cpu)"
    )
    args = parser.parse_args()

    export_params(args.ckpt, args.output, device=args.device)


if __name__ == "__main__":
    main()
